# I know this probably looks a bit ugly, but it works and that's what fucking counts

###################
#Generate 
rrnorm <- c(-10, 0, 10, 100)
(output <- tibble(v1 = 1:40, v2 = 1:40, v3 = 1:40, v4 = 1:40))
for (i in seq_along(rrnorm)) {
  output[[i]] <- rnorm(n = 10, mean = rrnorm[[i]])
}
output

####################
#Write the lyrics to "99 bottles of beer on the wall"
a <- "X bottles of beer on the wall, X bottles of beer.\n Take one down, pass it around, Y bottles of beer on the wall.\n\n"
output <- tibble(x = rep(""), y = 99:0)
for (i in seq_along(output$x)) {
  output$x[[i]] <- a
  output$x[[i]] <- str_replace_all(output$x[[i]], "X", as.character(output$y[[i]]))
  output$x[[i]] <- str_replace_all(output$x[[i]], "Y", as.character(output$y[[i]]-1))
  if (str_detect(output$x[[i]], "\\D1 bottles")) {
    output$x[[i]] <- str_replace_all(output$x[[i]], "1 bottles", "1 bottle")
  }
  if (str_detect(output$x[[i]], "^0 bottles")) {
    output$x[[i]] <- str_replace_all(output$x[[i]], "Take one down.*\\n", "Go to the store and buy some more, 99 bottles of beer on the wall.")
  }
}
cat(output$x)

#################
#Find the number of days it takes to get a full deck of cards
num.simulations = 10000
deck <- 1:52
full.deck <- function(collected) all(deck %in% collected)
lengths = vector(,num.simulations)

for (i in 1:num.simulations)
{
  collected <- c()

  while(!full.deck(collected))
  {
    collected <- c(collected, sample(52,1)) 
  }
  lengths[i] = length(collected)
}    
summary(lengths)

###################
#My first motherfucking useful function
#Get a list of duplicates in a column that save to the global environment. Version 2 
#will include a way to make a list out of those saved results, maybe
one_col_dupes <- function(dataframe, ...) {
  dupe.list <- dataframe %>% 
    group_by_(...) %>%
    summarise(n = n()) %>%
    filter(n > 1)
  dupe.list <<- print(dupe.list)
  dupe.filter <<- print(semi_join(dataframe, dupe.list, by = ...))
}
one_col_dupes(test, "numbers")
}
dupes(test, "word")

#################
#Copy a certain formatting between lots of different ggplot graphs even if the underlying data changes

esi_colors <- c("#1A4B2B", "#437A37", "#5A0000", "#022434", "#737C74", "#BCBEB9", "#75937f") #list of custom (aka ESI) colors

esi_formatting <- 
  list(scale_fill_manual(values = esi_colors),
  theme(axis.text.x = element_text(size = 12, family = "Arial"),
        axis.text.y = element_text(size = 14, family = "Arial"),
        panel.border = element_rect(color = "black", linetype = "solid", fill = NA),
        axis.title = element_text(size = 18, face = "bold", family = "Arial"),
        axis.title.x = element_blank(), 
        axis.title.y = element_text(size = 16, family = "Arial"),
        legend.position = "none",
        title = element_text(size = 18),
        strip.text = element_text(size = 13, face = "bold", family = "Arial"),
        strip.background = element_blank(),
        panel.background = element_blank()))

#Then simply do `+ esi_formatting` to the ggplots



###############
#Apply functions

#Get certain element from a list (e.g. a row or column)
(A <- matrix(1:9, nrow = 3, ncol = 3))
(B <- matrix(4:15, nrow = 4, ncol = 3))
(C <- matrix(8:10, nrow = 3, ncol = 2))
(MyList <- list(A, B, C))
lapply(MyList, "[", , 2) #Get everything in the second column
lapply(MyList, "[", 1, ) #Get everything in the first row
#Use sapply() or unlist() to turn the vector lists into a single vector of integers

#Do a massive gsub
survey <- 
  lapply(survey,
         function(x) {
           gsub("important", "Important", x) #Substitute "important" for "Important" across the entire dataset
         }
  ) 
# Do a massive fct_relevel
survey[92:124] <- (lapply(survey[92:124], fct_relevel,
                          "Not Important", "Somewhat Important", "Important", "Very Important", 
                          "Extremely Important", "N/A"))
# Arguments within fct_relevel, mean, range, or whatever the inner FUN is get tacked on to the end outside of the FUN parentheses

###############
## #Gathering the ethnicities
# ethnicities <- list(black, asian, white, hispanic)
# groups <- c("black", "asian", "white", "hispanic")
# rel_names <- str_replace_all(
#   names(ethnicities[[1]]), "[[[:punct:]]\\s]", "") #Take all punctuation junk out of relevant columns
# rel_names <- rel_names[c(3, 4, 22)] #Select only relevant columns
# 
# for (i in seq_along(ethnicities)) {
#   names(ethnicities[[i]]) <- str_replace_all(
#     names(ethnicities[[i]]), "[[[:punct:]]\\s]", "") #get rid of punct in names
#   ethnicities[[i]] <- ethnicities[[i]] %>%
#     select(rel_names)
#   rel_names2 <- c("Geography", groups[[i]], "group")
#   colnames(ethnicities[[i]]) <- rel_names2
#   ethnicities[[i]] <- ethnicities[[i]] %>%
#     select(-group)
# }
# ethnicities
# 
# (final_ethnicities <- bind_cols(ethnicities[1:4]) %>%
#   select(-matches("\\d$"))) #Getting rid of extra columns


#Massive str_replace_all ###########
a <- survey %>% #In downloading the file as a csv, excel converted many of the zip codes to numbers 
  mutate(`In what zip code do you live currently?Open-Ended Response` = 
           str_replace_all(`In what zip code do you live currently?Open-Ended Response`, c(
             "^8(?=\\d{3})" = "08", #Replaces 8 followed by three numbers with '08'
             "^9(?=\\d{3})" ="19",  #Replaces 9 followed by three numbers with '19'
             "[:alpha:]" =  "",     #Removes all alpha characters
             "^\\d{1,4}$" = "Other",#Zips with 4 or fewer numbers are replaced with "Other"
             ".*61.*" =  "08108"))) #One-off correction

#Using dplyr in functions##########
df <- tibble(
  g1 = c(1, 1, 2, 2, 2),
  g2 = c(1, 2, 1, 2, 1),
  a = sample(5), 
  b = sample(5)
)

my_summarise <- function(df, group_var, var) {
  df %>%
    group_by(!!group_var) %>%
    summarise(a = mean(a))
}
my_summarise(df, quo(g1))

# and making it easier:
my_summarise <- function(df, group_by, var) {
  group_by <- enquo(group_by)
  var <- enquo(var)
  print(group_by)
  
  df %>%
    group_by(!!group_by) %>%
    summarise(a = mean(!!var))
}
my_summarise(df, g1, a)

my_summarise2 <- function(df, expr) {
  expr <- enquo(expr)
  
  summarise(df, 
    mean = mean(!!expr),
    sum = sum(!!expr),
    n = n()
  )
}
my_summarise2(df, a * b)

my_mutate <- function(df, expr) {
  expr <- enquo(expr)
  mean_name <- paste0("mean_", quo_name(expr))
  sum_name <- paste0("sum_", quo_name(expr))
  
  mutate(df, 
    !!mean_name := mean(!!expr), 
    !!sum_name := sum(!!expr)
  )
}

my_mutate(df, a)

my_summarise <- function(df, ...) {
  group_by <- quos(...)

  df %>%
    group_by(!!!group_by) %>%
    summarise(a = mean(a))
}

my_summarise(df, g1, g2)

####################
# Importing multiple excel files into R and appending them
library(tidyverse) # these are library statements that require that you already have the package installed
                    # tidyverse is the most important series of packages for data analysis
library(readxl)    # readxl is a package for reading excel
library(RODBC)    # RODBC is a package for interfacing with databases (R - Open DataBase Connection) such as Access

setwd("Z:/Nestl√©/2020/Data/All Applicant Data")  # Sets the working directory, where all the applicant files are located
(file.list <- grep(pattern = "^((?!Old).)*(?=Compliance)+((?!Old).*)\\.xlsx$", x = list.files(recursive = T), perl = T,
                   value = T)) 
# grep is a text search function, using Regular Expressions to only select the files you need
# You will have to rewrite the working directory and the grep pattern text to detect ALL OF and ONLY the files you want
# For info on Regular Expresions in R, see this cheat sheet: https://rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf
# Site for testing regex (note that R requires \\ before something to use its special ability, while most other 
# sites including this one do not), see here: https://regex101.com/

(df.list <- sapply(file.list, read_excel, col_names = F, simplify = F)) #sapply is a function that applies a function to multiple things, 
    # in that it applies the function read_excel to file.list multiple times
    # it creates a list called df.list
    # For info on how file.list and df.list work together, see here: https://stackoverflow.com/questions/32888757/how-can-i-read-multiple-excel-files-into-r
    # use str() on any object to determine its structure

(Combined_Purina_App_Data <- bind_rows(df.list, .id = "File Source"))
